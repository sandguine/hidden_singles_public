{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path = '/home/ajhnam/projects/hidden_singles_public/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(proj_path + 'python/')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "from hiddensingles.misc import torch_utils as tu\n",
    "from hiddensingles.misc import utils, TensorDict, TensorDictDataset, RRN, DigitRRN\n",
    "from hiddensingles.experiment.sudoku_hs_service import create_tutorial, create_phase1, create_phase2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, dataset, num_steps=8):\n",
    "    outputs = model(dataset.inputs, num_steps=num_steps)\n",
    "    \n",
    "    goals = tu.expand_along_dim(dataset.goals, 1, num_steps)\n",
    "    goal_outputs = tu.select(outputs, goals, select_dims=1)\n",
    "    \n",
    "    targets = tu.expand_along_dim(dataset.targets, 1, num_steps)\n",
    "    goal_loss = tu.cross_entropy(goal_outputs, targets)\n",
    "    goal_probs = tu.select(goal_outputs.softmax(-1), dataset.targets)\n",
    "    goal_td = TensorDict(loss=goal_loss,\n",
    "                         probs=goal_probs,\n",
    "                         outputs=goal_outputs)\n",
    "    \n",
    "    coords = tu.expand_along_dim(dataset.coords, 1, num_steps)\n",
    "    out_exp = tu.expand_along_dim(outputs, 2, 9)\n",
    "    coord_outputs = tu.select(out_exp, coords, select_dims=1)\n",
    "    coord_targets = tu.expand_along_dim(dataset.coord_targets, 1, num_steps)\n",
    "    coord_loss = tu.cross_entropy(coord_outputs, coord_targets)\n",
    "    coord_probs = tu.select_subtensors(coord_outputs.softmax(-1), coord_targets)\n",
    "    coord_td = TensorDict(loss=coord_loss,\n",
    "                          probs=coord_probs,\n",
    "                          outputs=coord_outputs)\n",
    "\n",
    "    loss = goal_loss + coord_loss\n",
    "    return TensorDict(loss=loss,\n",
    "                      outputs=outputs,\n",
    "                      goal=goal_td,\n",
    "                      coord=coord_td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase2_conditions(phase2):\n",
    "    ht = [p.condition.house_type for p in phase2]\n",
    "    hi = [p.condition.house_index for p in phase2]\n",
    "    ci = [p.condition.cell_index for p in phase2]\n",
    "    ds = [p.condition.digit_set for p in phase2]\n",
    "    conditions = pd.DataFrame(np.array([ht, hi, ci, ds]).T,\n",
    "                              columns=['house_type', 'house_index', 'cell_index', 'digit_set'])\n",
    "    return conditions\n",
    "\n",
    "def hidden_singles_to_tensordict(list_of_hidden_singles, digit_rrn):\n",
    "    grids = torch.tensor([a.grid.array for a in list_of_hidden_singles], device=device)\n",
    "    goals = [p.coordinates['goal'] for p in list_of_hidden_singles]\n",
    "    goals = torch.tensor([[g.x, g.y] for g in goals], device=device)\n",
    "    targets = torch.tensor([a.digits['target'] for a in list_of_hidden_singles], device=device) - 1 # make it 0-8\n",
    "    coords = grids.nonzero()[:,1:].view(len(list_of_hidden_singles), -1, 2)\n",
    "    coord_targets = tu.select(tu.expand_along_dim(grids, 1, 9), coords) - 1 # make it 0-8\n",
    "    \n",
    "    inputs = DigitRRN.make_onehot(grids) if digit_rrn else grids\n",
    "    return TensorDict(inputs=inputs,\n",
    "                      grids=grids,\n",
    "                      goals=goals,\n",
    "                      targets=targets,\n",
    "                      coords=coords,\n",
    "                      coord_targets=coord_targets)\n",
    "\n",
    "def create_dataset(num_train, num_valid, digit_rrn=False):\n",
    "    digit_set1 = set(random.sample(set(range(1, 10)), 4))\n",
    "    digit_set2 = set(random.sample(set(range(1, 10)) - digit_set1, 4))\n",
    "    tutorial = create_tutorial(digit_set1)\n",
    "    phase1 = create_phase1(tutorial, num_train + num_valid)\n",
    "    phase2 = create_phase2(tutorial, digit_set1, digit_set2)\n",
    "    conditions = get_phase2_conditions(phase2)\n",
    "\n",
    "    phase1 = hidden_singles_to_tensordict(phase1, digit_rrn=digit_rrn)\n",
    "    phase2 = hidden_singles_to_tensordict([p.hidden_single for p in phase2], digit_rrn=digit_rrn)\n",
    "    \n",
    "    dataset = TensorDict(train=phase1[:num_train],\n",
    "                         valid=phase1[num_train:],\n",
    "                         test=phase2)\n",
    "    return dataset, conditions\n",
    "\n",
    "def train_model(model, dataset, num_steps=8,\n",
    "                batch_size=100, num_epochs=100, lr=1e-3,\n",
    "                record_epoch=1, show_pbar=True, verbose=False):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    dataloader = DataLoader(TensorDictDataset(dataset.train), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    iterator = range(num_epochs + 1)\n",
    "    if show_pbar:\n",
    "        iterator = tqdm(iterator, leave=False)\n",
    "\n",
    "    all_results = []\n",
    "    \n",
    "    for i in iterator:\n",
    "        epoch_results = []\n",
    "        \n",
    "        if i%record_epoch == 0:\n",
    "            with torch.no_grad():\n",
    "                v_results = get_results(model, dataset.valid)\n",
    "            v_predictions = v_results.goal.outputs[:,-1].argmax(-1)\n",
    "            v_accuracy = (v_predictions == dataset.valid.targets).float().mean().item()\n",
    "            v_probability = v_results.goal.probs[:,-1].mean().item()\n",
    "            \n",
    "        goal_loss = []\n",
    "        for dset in dataloader:\n",
    "            dset = TensorDict(**dset)\n",
    "            optimizer.zero_grad()\n",
    "            results = get_results(model, dset, num_steps=num_steps)\n",
    "            \n",
    "            goal_loss.append(results.goal.loss.item())\n",
    "            results.loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i%record_epoch == 0:\n",
    "                predictions = results.goal.outputs[:,-1].argmax(-1)\n",
    "                correct = (predictions == dset.targets)\n",
    "                results.goal.correct = correct\n",
    "                epoch_results.append(results.goal[['correct', 'probs']].detach())\n",
    "            \n",
    "        if i%record_epoch == 0:\n",
    "            epoch_results = TensorDict.cat(epoch_results, dim=0)\n",
    "            tr_accuracy = epoch_results.correct.float().mean().item()\n",
    "            tr_probability = epoch_results.probs[:,-1].mean().item()\n",
    "            \n",
    "            row = {'epoch': i,\n",
    "                   'loss': np.mean(goal_loss),\n",
    "                   'tr_probability': tr_probability,\n",
    "                   'tr_accuracy': tr_accuracy,\n",
    "                   'v_probability': v_probability,\n",
    "                   'v_accuracy': v_accuracy}\n",
    "            all_results.append(row)\n",
    "            \n",
    "            if verbose:\n",
    "                utils.kv_print(**row)\n",
    "                \n",
    "    results = pd.DataFrame(all_results)\n",
    "    return results\n",
    "\n",
    "def get_test_results(model, dataset, conditions):\n",
    "    with torch.no_grad():\n",
    "        results = get_results(model, dataset.test)\n",
    "        \n",
    "    goal_probs = results.goal.probs[:,-1].cpu().numpy()\n",
    "    predictions = results.goal.outputs[:,-1].argmax(-1)\n",
    "    correct = (predictions == dataset.test.targets).cpu().numpy()\n",
    "    \n",
    "    test_results = conditions.copy()\n",
    "    test_results['probability'] = goal_probs\n",
    "    test_results['correct'] = correct\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5051c2622145c6831cce036f13a1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_train_results = []\n",
    "all_test_results = []\n",
    "for num_train in tqdm([25, 50, 100, 200, 300, 400, 500]):\n",
    "    model = RRN(digit_embed_size=10,\n",
    "                num_mlp_layers=0,\n",
    "                hidden_vector_size=48,\n",
    "                message_size=48,\n",
    "                encode_coordinates=False).to(device)\n",
    "    dataset, conditions = create_dataset(num_train=num_train, num_valid=100, digit_rrn=False)\n",
    "    train_results = train_model(model, dataset, num_steps=8, batch_size=100,\n",
    "                                num_epochs=1000, record_epoch=10, verbose=False)\n",
    "    test_results = get_test_results(model, dataset, conditions)\n",
    "    train_results['train_size'] = num_train\n",
    "    test_results['train_size'] = num_train\n",
    "    \n",
    "    all_train_results.append(train_results)\n",
    "    all_test_results.append(test_results)\n",
    "    \n",
    "train_results = pd.concat(all_train_results)\n",
    "test_results = pd.concat(all_test_results)\n",
    "\n",
    "train_results = train_results[['train_size', 'epoch', 'loss',\n",
    "                               'tr_accuracy', 'tr_probability', 'v_accuracy', 'v_probability']]\n",
    "test_results = test_results[['train_size', 'house_type', 'house_index', 'cell_index',\n",
    "                             'digit_set', 'correct', 'probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "dirpath = proj_path + 'data/rrn/'\n",
    "utils.mkdir(dirpath)\n",
    "\n",
    "train_results.to_csv(dirpath + \"rrn_train_results.tsv\", sep='\\t', index=False)\n",
    "test_results.to_csv(dirpath + \"rrn_test_results.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit RRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a62599e3c34dcca21bfa39efbca3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=501.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=501.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=501.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_train_results = []\n",
    "all_test_results = []\n",
    "for num_train in tqdm([25, 50, 100]):\n",
    "    model = DigitRRN(hidden_vector_size=8,\n",
    "                     message_size=8).to(device)\n",
    "    dataset, conditions = create_dataset(num_train=num_train, num_valid=100, digit_rrn=True)\n",
    "    train_results = train_model(model, dataset, num_steps=8, batch_size=20,\n",
    "                                num_epochs=500, record_epoch=1, verbose=False)\n",
    "    test_results = get_test_results(model, dataset, conditions)\n",
    "    train_results['train_size'] = num_train\n",
    "    test_results['train_size'] = num_train\n",
    "    \n",
    "    all_train_results.append(train_results)\n",
    "    all_test_results.append(test_results)\n",
    "    \n",
    "train_results = pd.concat(all_train_results)\n",
    "test_results = pd.concat(all_test_results)\n",
    "\n",
    "train_results = train_results[['train_size', 'epoch', 'loss',\n",
    "                               'tr_accuracy', 'tr_probability', 'v_accuracy', 'v_probability']]\n",
    "test_results = test_results[['train_size', 'house_type', 'house_index', 'cell_index',\n",
    "                             'digit_set', 'correct', 'probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "dirpath = proj_path + 'data/rrn/'\n",
    "utils.mkdir(dirpath)\n",
    "\n",
    "train_results.to_csv(dirpath + \"drrn_train_results.tsv\", sep='\\t', index=False)\n",
    "test_results.to_csv(dirpath + \"drrn_test_results.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
