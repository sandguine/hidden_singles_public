{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path = '/home/ajhnam/projects/hidden_singles_public/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(proj_path + 'python/')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from hiddensingles.misc import torch_utils as tu\n",
    "from hiddensingles.misc import utils, TensorDict, TensorDictDataset, RRN\n",
    "from hiddensingles.sudoku.grid import GridString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_seed_puzzles(df, op):\n",
    "    \"\"\"\n",
    "    Flips puzzles and solutions of all puzzles and solutions in the dataframe\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    puzzles_flip = [flip_gridstring(gs, op) for gs in df.puzzle]\n",
    "    solutions_flip = [flip_gridstring(gs, op) for gs in df.solution]\n",
    "    puzzles_flip, solutions_flip = zip(*[make_seed(p, s) for p, s in zip(puzzles_flip, solutions_flip)])\n",
    "    df[['puzzle', 'solution']] = np.array([puzzles_flip, solutions_flip]).T\n",
    "    return df\n",
    "\n",
    "def flip_gridstring(gridstring: str, op: str):\n",
    "    assert op in ('lr', 'ud', 'both')\n",
    "    \n",
    "    gridstring = GridString.load(gridstring)\n",
    "    array = gridstring.array()\n",
    "    \n",
    "    if op == 'lr':\n",
    "        array = np.fliplr(array)\n",
    "    elif op == 'ud':\n",
    "        array = np.flipud(array)\n",
    "    else:\n",
    "        array = np.flip(array)\n",
    "        \n",
    "    gridstring = GridString.load_array(gridstring.dim_x, gridstring.dim_y, array)\n",
    "    return str(gridstring)\n",
    "\n",
    "def map_digits(puzzle_gs: str, solution_gs: str, mapping: dict):\n",
    "    puzzle_gs = GridString.load(puzzle_gs).map_digits(mapping)\n",
    "    solution_gs = GridString.load(solution_gs).map_digits(mapping)\n",
    "    return str(puzzle_gs), str(solution_gs)\n",
    "\n",
    "def make_seed(puzzle_gs: str, solution_gs: str):\n",
    "    solution_gs = GridString.load(solution_gs)\n",
    "    mapping = solution_gs.seed_mapping()\n",
    "    \n",
    "    solution_gs = solution_gs.map_digits(mapping)\n",
    "    puzzle_gs = GridString.load(puzzle_gs).map_digits(mapping)\n",
    "    return str(puzzle_gs), str(solution_gs)\n",
    "\n",
    "def random_map(puzzle_gs: str, solution_gs: str):\n",
    "    puzzle = GridString.load(puzzle_gs)\n",
    "    solution = GridString.load(solution_gs)\n",
    "    \n",
    "    mapping = {i: j for i, j in zip(range(1, puzzle.max_digit), 1 + np.random.permutation(puzzle.max_digit))}\n",
    "    puzzle = puzzle.map_digits(mapping)\n",
    "    solution = solution.map_digits(mapping)\n",
    "\n",
    "    return str(puzzle), str(solution)\n",
    "\n",
    "def random_map_df(df):\n",
    "    \"\"\"\n",
    "    Applies random_map to all puzzles and solutions in the dataframe\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    puzzles, solutions = zip(*[random_map(p, s) for p, s in zip(df.puzzle, df.solution)])\n",
    "    df[['puzzle', 'solution']] = np.array([puzzles, solutions]).T\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, dataset, batch_size, num_steps=16, optimizer=None):\n",
    "    train = optimizer is not None\n",
    "    \n",
    "    dataloader = DataLoader(TensorDictDataset(dataset), batch_size=batch_size, shuffle=train)\n",
    "    \n",
    "    losses = []\n",
    "    correct = []\n",
    "    for dset in dataloader:\n",
    "        dset = TensorDict(**dset)\n",
    "        \n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(dset.inputs, num_steps=num_steps)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(dset.inputs, num_steps=num_steps)\n",
    "        outputs = outputs.view(-1, num_steps, model.max_digit, model.max_digit, model.max_digit)\n",
    "        targets = tu.expand_along_dim(dset.targets, 1, num_steps)\n",
    "        loss = tu.cross_entropy(outputs, targets)\n",
    "        \n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # record\n",
    "        losses.append(loss.item())\n",
    "        correct.append((outputs.argmax(-1) == targets)[:,-1])\n",
    "    \n",
    "    correct = torch.cat(correct)\n",
    "    loss = torch.tensor(losses).mean()\n",
    "    accuracy = correct.float().mean().cpu()\n",
    "    solved = correct.all(-1).all(-1).float().mean().cpu()\n",
    "    \n",
    "    results = TensorDict(loss=loss,\n",
    "                         accuracy=accuracy,\n",
    "                         solved=solved)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample_multiplier = 2 # Creates 800*N training samples and 200*N test samples\n",
    "\n",
    "df_puzzles = pd.read_csv(proj_path + '/data/2x3_puzzle_seeds.tsv', sep='\\t')\n",
    "\n",
    "# Select only puzzles with 17 hints, remove puzzles with same solutions\n",
    "df_puzzles = df_puzzles[(df_puzzles.num_hints == 17)].drop_duplicates('solution').reset_index(drop=True)\n",
    "\n",
    "# Create flipped versions of the same puzzles\n",
    "df_puzzles['seed_sol'] = df_puzzles.solution\n",
    "df_flip = flip_seed_puzzles(df_puzzles, 'both')\n",
    "df_fliplr = flip_seed_puzzles(df_puzzles, 'lr')\n",
    "df_flipud = flip_seed_puzzles(df_puzzles, 'ud')\n",
    "df_puzzles = pd.concat([df_puzzles, df_flip, df_fliplr, df_flipud]).drop_duplicates('solution')\n",
    "\n",
    "# Only choose seed solutions where all 4 orientations exist\n",
    "counts = df_puzzles.groupby('seed_sol').count()\n",
    "seed_sols = counts[counts.puzzle == 4].reset_index()[['seed_sol']].head(250)\n",
    "seed_sols['train'] = [i < 200 for i in range(250)]\n",
    "df_puzzles = df_puzzles.merge(seed_sols)\n",
    "df_puzzles = df_puzzles[['train', 'puzzle', 'solution']]\n",
    "\n",
    "# Create multiple versions of same puzzles by shuffling digits\n",
    "df_puzzles = pd.concat([random_map_df(df_puzzles) for i in range(num_sample_multiplier)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn puzzles into tensors\n",
    "\n",
    "inputs = torch.tensor([GridString.load(p).array() for p in df_puzzles[df_puzzles.train].puzzle])\n",
    "targets = -1 + torch.tensor([GridString.load(p).array() for p in df_puzzles[df_puzzles.train].solution])\n",
    "train_dset = TensorDict(inputs=inputs, targets=targets).to(device)\n",
    "inputs = torch.tensor([GridString.load(p).array() for p in df_puzzles[~df_puzzles.train].puzzle])\n",
    "targets = -1 + torch.tensor([GridString.load(p).array() for p in df_puzzles[~df_puzzles.train].solution])\n",
    "test_dset = TensorDict(inputs=inputs, targets=targets).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RRN(dim_x=2,\n",
    "            dim_y=3,\n",
    "            digit_embed_size=7,\n",
    "            num_mlp_layers=0,\n",
    "            hidden_vector_size=48,\n",
    "            message_size=48,\n",
    "            encode_coordinates=False).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee91d4f31a0e48f8bad80384e3159447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | loss: 1.746 | tr_acc: 0.303 | tr_sol: 0.0 | te_acc: 0.301 | te_sol: 0.0\n",
      "epoch: 10 | loss: 1.04 | tr_acc: 0.696 | tr_sol: 0.0 | te_acc: 0.7 | te_sol: 0.0\n",
      "epoch: 20 | loss: 0.722 | tr_acc: 0.808 | tr_sol: 0.001 | te_acc: 0.814 | te_sol: 0.0\n",
      "epoch: 30 | loss: 0.561 | tr_acc: 0.861 | tr_sol: 0.008 | te_acc: 0.855 | te_sol: 0.015\n",
      "epoch: 40 | loss: 0.44 | tr_acc: 0.914 | tr_sol: 0.102 | te_acc: 0.896 | te_sol: 0.052\n",
      "epoch: 50 | loss: 0.38 | tr_acc: 0.929 | tr_sol: 0.169 | te_acc: 0.917 | te_sol: 0.107\n",
      "epoch: 60 | loss: 0.344 | tr_acc: 0.94 | tr_sol: 0.244 | te_acc: 0.925 | te_sol: 0.16\n",
      "epoch: 70 | loss: 0.316 | tr_acc: 0.946 | tr_sol: 0.282 | te_acc: 0.927 | te_sol: 0.212\n",
      "epoch: 80 | loss: 0.284 | tr_acc: 0.959 | tr_sol: 0.414 | te_acc: 0.94 | te_sol: 0.34\n",
      "epoch: 90 | loss: 0.262 | tr_acc: 0.967 | tr_sol: 0.507 | te_acc: 0.95 | te_sol: 0.415\n",
      "epoch: 100 | loss: 0.242 | tr_acc: 0.973 | tr_sol: 0.589 | te_acc: 0.956 | te_sol: 0.477\n",
      "epoch: 110 | loss: 0.222 | tr_acc: 0.981 | tr_sol: 0.704 | te_acc: 0.961 | te_sol: 0.542\n",
      "epoch: 120 | loss: 0.209 | tr_acc: 0.984 | tr_sol: 0.736 | te_acc: 0.965 | te_sol: 0.607\n",
      "epoch: 130 | loss: 0.196 | tr_acc: 0.989 | tr_sol: 0.817 | te_acc: 0.97 | te_sol: 0.657\n",
      "epoch: 140 | loss: 0.188 | tr_acc: 0.989 | tr_sol: 0.822 | te_acc: 0.973 | te_sol: 0.712\n",
      "epoch: 150 | loss: 0.18 | tr_acc: 0.992 | tr_sol: 0.857 | te_acc: 0.975 | te_sol: 0.732\n",
      "epoch: 160 | loss: 0.172 | tr_acc: 0.994 | tr_sol: 0.896 | te_acc: 0.973 | te_sol: 0.725\n",
      "epoch: 170 | loss: 0.169 | tr_acc: 0.993 | tr_sol: 0.896 | te_acc: 0.974 | te_sol: 0.732\n",
      "epoch: 180 | loss: 0.165 | tr_acc: 0.994 | tr_sol: 0.903 | te_acc: 0.979 | te_sol: 0.787\n",
      "epoch: 190 | loss: 0.16 | tr_acc: 0.996 | tr_sol: 0.924 | te_acc: 0.975 | te_sol: 0.755\n",
      "epoch: 200 | loss: 0.156 | tr_acc: 0.996 | tr_sol: 0.943 | te_acc: 0.978 | te_sol: 0.787\n",
      "epoch: 210 | loss: 0.151 | tr_acc: 0.997 | tr_sol: 0.962 | te_acc: 0.977 | te_sol: 0.782\n",
      "epoch: 220 | loss: 0.146 | tr_acc: 0.999 | tr_sol: 0.982 | te_acc: 0.979 | te_sol: 0.805\n",
      "epoch: 230 | loss: 0.154 | tr_acc: 0.995 | tr_sol: 0.927 | te_acc: 0.976 | te_sol: 0.765\n",
      "epoch: 240 | loss: 0.149 | tr_acc: 0.997 | tr_sol: 0.961 | te_acc: 0.98 | te_sol: 0.815\n",
      "epoch: 250 | loss: 0.14 | tr_acc: 0.999 | tr_sol: 0.991 | te_acc: 0.979 | te_sol: 0.815\n",
      "epoch: 260 | loss: 0.144 | tr_acc: 0.998 | tr_sol: 0.967 | te_acc: 0.978 | te_sol: 0.79\n",
      "epoch: 270 | loss: 0.137 | tr_acc: 1.0 | tr_sol: 0.997 | te_acc: 0.981 | te_sol: 0.835\n",
      "epoch: 280 | loss: 0.135 | tr_acc: 1.0 | tr_sol: 0.998 | te_acc: 0.981 | te_sol: 0.835\n",
      "epoch: 290 | loss: 0.134 | tr_acc: 1.0 | tr_sol: 0.994 | te_acc: 0.981 | te_sol: 0.832\n",
      "epoch: 300 | loss: 0.141 | tr_acc: 0.998 | tr_sol: 0.969 | te_acc: 0.98 | te_sol: 0.827\n",
      "epoch: 310 | loss: 0.149 | tr_acc: 0.994 | tr_sol: 0.913 | te_acc: 0.98 | te_sol: 0.825\n",
      "epoch: 320 | loss: 0.139 | tr_acc: 0.998 | tr_sol: 0.967 | te_acc: 0.982 | te_sol: 0.847\n",
      "epoch: 330 | loss: 0.132 | tr_acc: 1.0 | tr_sol: 0.995 | te_acc: 0.981 | te_sol: 0.832\n",
      "epoch: 340 | loss: 0.13 | tr_acc: 1.0 | tr_sol: 0.999 | te_acc: 0.98 | te_sol: 0.835\n",
      "epoch: 350 | loss: 0.129 | tr_acc: 1.0 | tr_sol: 0.999 | te_acc: 0.981 | te_sol: 0.845\n",
      "epoch: 360 | loss: 0.128 | tr_acc: 1.0 | tr_sol: 0.999 | te_acc: 0.98 | te_sol: 0.835\n",
      "epoch: 370 | loss: 0.128 | tr_acc: 1.0 | tr_sol: 0.999 | te_acc: 0.98 | te_sol: 0.837\n",
      "epoch: 380 | loss: 0.127 | tr_acc: 1.0 | tr_sol: 0.999 | te_acc: 0.98 | te_sol: 0.827\n",
      "epoch: 390 | loss: 0.126 | tr_acc: 1.0 | tr_sol: 0.999 | te_acc: 0.98 | te_sol: 0.83\n",
      "epoch: 400 | loss: 0.135 | tr_acc: 0.998 | tr_sol: 0.968 | te_acc: 0.979 | te_sol: 0.822\n",
      "epoch: 410 | loss: 0.14 | tr_acc: 0.996 | tr_sol: 0.946 | te_acc: 0.978 | te_sol: 0.817\n",
      "epoch: 420 | loss: 0.135 | tr_acc: 0.998 | tr_sol: 0.974 | te_acc: 0.976 | te_sol: 0.79\n",
      "epoch: 430 | loss: 0.131 | tr_acc: 0.999 | tr_sol: 0.989 | te_acc: 0.98 | te_sol: 0.84\n",
      "epoch: 440 | loss: 0.129 | tr_acc: 1.0 | tr_sol: 0.995 | te_acc: 0.981 | te_sol: 0.85\n",
      "epoch: 450 | loss: 0.125 | tr_acc: 1.0 | tr_sol: 0.999 | te_acc: 0.981 | te_sol: 0.857\n",
      "epoch: 460 | loss: 0.124 | tr_acc: 1.0 | tr_sol: 0.999 | te_acc: 0.981 | te_sol: 0.847\n",
      "epoch: 470 | loss: 0.123 | tr_acc: 1.0 | tr_sol: 1.0 | te_acc: 0.981 | te_sol: 0.847\n",
      "epoch: 480 | loss: 0.123 | tr_acc: 1.0 | tr_sol: 1.0 | te_acc: 0.981 | te_sol: 0.842\n",
      "epoch: 490 | loss: 0.122 | tr_acc: 1.0 | tr_sol: 1.0 | te_acc: 0.98 | te_sol: 0.837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps = 16\n",
    "batch_size = 400\n",
    "num_epochs = 500\n",
    "print_epochs = 10\n",
    "\n",
    "tr_result = get_results(model, train_dset, batch_size=batch_size, num_steps=num_steps)\n",
    "te_result = get_results(model, test_dset, batch_size=batch_size, num_steps=num_steps)\n",
    "tr_results = [tr_result]\n",
    "te_results = [te_result]\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    tr_result = get_results(model, train_dset, batch_size=batch_size, num_steps=num_steps, optimizer=optimizer)\n",
    "    tr_results.append(tr_result)\n",
    "    te_result = get_results(model, test_dset, batch_size=batch_size, num_steps=num_steps)\n",
    "    te_results.append(te_result)\n",
    "\n",
    "    if epoch % print_epochs == 0:\n",
    "        utils.kv_print(epoch=epoch, loss=tr_result.loss,\n",
    "                       tr_acc=tr_result.accuracy, tr_sol=tr_result.solved,\n",
    "                       te_acc=te_result.accuracy, te_sol=te_result.solved)\n",
    "        \n",
    "tr_results = TensorDict.stack(tr_results, 0)\n",
    "te_results = TensorDict.stack(te_results, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = tr_results.to_dataframe({0: 'epoch'})\n",
    "tr_df['dataset'] = 'train'\n",
    "te_df = te_results.to_dataframe({0: 'epoch'})\n",
    "te_df['dataset'] = 'test'\n",
    "df = pd.concat([tr_df, te_df])\n",
    "\n",
    "df.to_csv(proj_path + \"data/rrn/sudoku_2x3_results.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
