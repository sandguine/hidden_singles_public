{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path = '/home/ajhnam/projects/hidden_singles_public/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(proj_path + 'python/')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "from hiddensingles.misc import torch_utils as tu\n",
    "from hiddensingles.misc import utils, TensorDict, TensorDictDataset, nnModule, MLP\n",
    "from hiddensingles.experiment.sudoku_hs_service import create_tutorial, create_phase1, create_phase2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(dim_x, dim_y, device='cpu'):\n",
    "    \"\"\"\n",
    "    Returns a boolean tensor of shape [(dim_x * dim_y)^2, (dim_x * dim_y)^2]\n",
    "    indicating whether the ith cell is a neighbor of the jth cell\n",
    "    \"\"\"\n",
    "    max_digit = dim_x * dim_y\n",
    "    num_cells = max_digit**2\n",
    "    coords = utils.get_combinations(range(max_digit), range(max_digit))\n",
    "    neighbors = np.zeros((num_cells, num_cells), dtype=bool)\n",
    "    for i, j in itertools.product(range(len(coords)), range(len(coords))):\n",
    "        x1, y1 = coords[i]\n",
    "        x2, y2 = coords[j]\n",
    "        if x1 == x2 and y1 == y2:\n",
    "            continue\n",
    "        if x1 == x2 or y1 == y2:\n",
    "            neighbors[i, j] = True\n",
    "        elif x1 // dim_x == x2 // dim_x and y1 // dim_y == y2 // dim_y:\n",
    "            neighbors[i, j] = True\n",
    "\n",
    "    return torch.tensor(neighbors, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRN(nnModule):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dim_x=3,\n",
    "                 dim_y=3,\n",
    "                 digit_embed_size=10,\n",
    "                 hidden_vector_size=64,\n",
    "                 message_size=64):\n",
    "        super().__init__()\n",
    "        self.dim_x = dim_x\n",
    "        self.dim_y = dim_y\n",
    "        self.digit_embed_size = digit_embed_size\n",
    "        self.hidden_vector_size = hidden_vector_size\n",
    "        self.message_size = message_size\n",
    "        \n",
    "        self.num_embed = nn.Embedding(1 + self.max_digit, digit_embed_size)\n",
    "        self.message_linear = nn.Linear(hidden_vector_size+hidden_vector_size, message_size)\n",
    "        self.update_node_linear = nn.Linear(digit_embed_size+message_size, hidden_vector_size)\n",
    "        self.update_node_lstm = nn.LSTM(hidden_vector_size, hidden_vector_size)\n",
    "        self.output_linear = nn.Linear(hidden_vector_size, self.max_digit)\n",
    "        \n",
    "        # reusable tensors that can be pre-computed\n",
    "        neighbors = get_neighbors(dim_x, dim_y)\n",
    "        self.neighbors = torch.where(neighbors)[1].view((dim_x*dim_y)**2, -1)\n",
    "        \n",
    "        self.grid_x, self.grid_y = torch.meshgrid(torch.arange(self.max_digit),\n",
    "                                                  torch.arange(self.max_digit))\n",
    "        \n",
    "    @property\n",
    "    def max_digit(self):\n",
    "        return self.dim_x * self.dim_y\n",
    "    \n",
    "    @property\n",
    "    def num_cells(self):\n",
    "        return self.max_digit**2\n",
    "    \n",
    "    @property\n",
    "    def num_neighbors(self):\n",
    "        return self.neighbors.shape[-1]\n",
    "    \n",
    "    def get_neighbor_embeds(self, state):\n",
    "        \"\"\"\n",
    "        state: tensor of shape [batch_size, num_cells, hidden_vector_size]\n",
    "        return: tensor of shape [batch_size, num_cells, num_neighbors, hidden_vector_size]\n",
    "        \"\"\"\n",
    "        batch_size = state.shape[0]\n",
    "        self.neighbors = self.neighbors.to(state.device)\n",
    "        \n",
    "        neighbors = tu.prepend_shape(self.neighbors, batch_size)\n",
    "        state = tu.expand_along_dim(state, 1, self.num_cells)\n",
    "        return tu.select_subtensors_at(state, neighbors)\n",
    "    \n",
    "    def get_message_vectors(self, state):\n",
    "        \"\"\"\n",
    "        state: tensor of shape [batch_size, num_cells, hidden_vector_size]\n",
    "        return: tensor of shape [batch_size, num_cells, message_size]\n",
    "        \"\"\"\n",
    "        neighbors = self.get_neighbor_embeds(state)\n",
    "        state = tu.expand_along_dim(state, 2, self.num_neighbors)\n",
    "        messages = self.message_linear(torch.cat([state, neighbors], dim=-1))\n",
    "        return messages.sum(dim=2)\n",
    "    \n",
    "    def get_input_embedding(self, grids):\n",
    "        input_embed = self.num_embed(grids).view(-1, self.num_cells, self.digit_embed_size)\n",
    "        return input_embed\n",
    "        \n",
    "    def forward(self, grids, num_steps=16):\n",
    "        batch_size = grids.shape[0]\n",
    "        device = grids.device\n",
    "        batch_size = len(grids)\n",
    "        outputs = []\n",
    "        \n",
    "        input_embed = self.get_input_embedding(grids)\n",
    "        \n",
    "        lstm_ch = None\n",
    "        messages = torch.zeros(batch_size, self.num_cells, self.message_size, device=device)\n",
    "        for i in range(num_steps):\n",
    "            lstm_inputs = self.update_node_linear(torch.cat([input_embed, messages], dim=-1)) # [batch_size, num_cells, hidden_vector_size]\n",
    "            lstm_inputs = lstm_inputs.view(1, batch_size*self.num_cells, self.hidden_vector_size)\n",
    "            state, lstm_ch = self.update_node_lstm(lstm_inputs, lstm_ch)\n",
    "            state = state.view(batch_size, self.num_cells, self.hidden_vector_size)\n",
    "            \n",
    "            if i < num_steps - 1: # if not the last step\n",
    "                messages = self.get_message_vectors(state)\n",
    "                \n",
    "            output = self.output_linear(state)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        outputs = outputs.view(batch_size, num_steps, self.max_digit, self.max_digit, self.max_digit)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, dataset, num_steps=8):\n",
    "    outputs = model(dataset.inputs, num_steps=num_steps)\n",
    "    \n",
    "    goals = tu.expand_along_dim(dataset.goals, 1, num_steps)\n",
    "    goal_outputs = tu.select(outputs, goals, select_dims=1)\n",
    "    \n",
    "    targets = tu.expand_along_dim(dataset.targets, 1, num_steps)\n",
    "    goal_loss = tu.cross_entropy(goal_outputs, targets)\n",
    "    goal_probs = tu.select(goal_outputs.softmax(-1), dataset.targets)\n",
    "    goal_td = TensorDict(loss=goal_loss,\n",
    "                         probs=goal_probs,\n",
    "                         outputs=goal_outputs)\n",
    "    \n",
    "    coords = tu.expand_along_dim(dataset.coords, 1, num_steps)\n",
    "    out_exp = tu.expand_along_dim(outputs, 2, 9)\n",
    "    coord_outputs = tu.select(out_exp, coords, select_dims=1)\n",
    "    coord_targets = tu.expand_along_dim(dataset.coord_targets, 1, num_steps)\n",
    "    coord_loss = tu.cross_entropy(coord_outputs, coord_targets)\n",
    "    coord_probs = tu.select_subtensors(coord_outputs.softmax(-1), coord_targets)\n",
    "    coord_td = TensorDict(loss=coord_loss,\n",
    "                          probs=coord_probs,\n",
    "                          outputs=coord_outputs)\n",
    "\n",
    "    loss = goal_loss + coord_loss\n",
    "    return TensorDict(loss=loss,\n",
    "                      outputs=outputs,\n",
    "                      goal=goal_td,\n",
    "                      coord=coord_td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase2_conditions(phase2):\n",
    "    ht = [p.condition.house_type for p in phase2]\n",
    "    hi = [p.condition.house_index for p in phase2]\n",
    "    ci = [p.condition.cell_index for p in phase2]\n",
    "    ds = [p.condition.digit_set for p in phase2]\n",
    "    conditions = pd.DataFrame(np.array([ht, hi, ci, ds]).T,\n",
    "                              columns=['house_type', 'house_index', 'cell_index', 'digit_set'])\n",
    "    return conditions\n",
    "\n",
    "def hidden_singles_to_tensordict(list_of_hidden_singles):\n",
    "    grids = torch.tensor([a.grid.array for a in list_of_hidden_singles], device=device)\n",
    "    goals = [p.coordinates['goal'] for p in list_of_hidden_singles]\n",
    "    goals = torch.tensor([[g.x, g.y] for g in goals], device=device)\n",
    "    targets = torch.tensor([a.digits['target'] for a in list_of_hidden_singles], device=device) - 1 # make it 0-8\n",
    "    coords = grids.nonzero()[:,1:].view(len(list_of_hidden_singles), -1, 2)\n",
    "    coord_targets = tu.select(tu.expand_along_dim(grids, 1, 9), coords) - 1 # make it 0-8\n",
    "    \n",
    "    return TensorDict(inputs=grids,\n",
    "                      goals=goals,\n",
    "                      targets=targets,\n",
    "                      coords=coords,\n",
    "                      coord_targets=coord_targets)\n",
    "\n",
    "def create_dataset(num_train, num_valid):\n",
    "    digit_set1 = set(random.sample(set(range(1, 10)), 4))\n",
    "    digit_set2 = set(random.sample(set(range(1, 10)) - digit_set1, 4))\n",
    "    tutorial = create_tutorial(digit_set1)\n",
    "    phase1 = create_phase1(tutorial, num_train + num_valid)\n",
    "    phase2 = create_phase2(tutorial, digit_set1, digit_set2)\n",
    "    conditions = get_phase2_conditions(phase2)\n",
    "\n",
    "    phase1 = hidden_singles_to_tensordict(phase1)\n",
    "    phase2 = hidden_singles_to_tensordict([p.hidden_single for p in phase2])\n",
    "    \n",
    "    dataset = TensorDict(train=phase1[:num_train],\n",
    "                         valid=phase1[num_train:],\n",
    "                         test=phase2)\n",
    "    return dataset, conditions\n",
    "\n",
    "def train_model(model, dataset, num_epochs=100, record_epoch=1, verbose=False):\n",
    "    num_steps = 8\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    dataloader = DataLoader(TensorDictDataset(dataset.train), batch_size=100, shuffle=True)\n",
    "    \n",
    "    iterator = range(num_epochs + 1)\n",
    "    if verbose:\n",
    "        iterator = tqdm(iterator)\n",
    "\n",
    "    all_results = []\n",
    "    \n",
    "    for i in iterator:\n",
    "        if i%record_epoch == 0:\n",
    "            with torch.no_grad():\n",
    "                v_results = get_results(model, dataset.valid)\n",
    "            predictions = v_results.goal.outputs[:,-1].argmax(-1)\n",
    "            accuracy = (predictions == dataset.valid.targets).float().mean().item()\n",
    "            probability = v_results.goal.probs[:,-1].mean().item()\n",
    "            \n",
    "        goal_loss = []\n",
    "        for dset in dataloader:\n",
    "            dset = TensorDict(**dset)\n",
    "            optimizer.zero_grad()\n",
    "            results = get_results(model, dset, num_steps=num_steps)\n",
    "            goal_loss.append(results.goal.loss.item())\n",
    "            results.loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if i%record_epoch == 0:\n",
    "            row = {'epoch': i,\n",
    "                   'loss': np.mean(goal_loss),\n",
    "                   'probability': probability,\n",
    "                   'accuracy': accuracy}\n",
    "            all_results.append(row)\n",
    "            \n",
    "            if verbose:\n",
    "                utils.kv_print(**row)\n",
    "                \n",
    "    results = pd.DataFrame(all_results)\n",
    "    return results\n",
    "\n",
    "def get_test_results(model, dataset, conditions):\n",
    "    with torch.no_grad():\n",
    "        results = get_results(model, dataset.test)\n",
    "        \n",
    "    goal_probs = results.goal.probs[:,-1].cpu().numpy()\n",
    "    predictions = results.goal.outputs[:,-1].argmax(-1)\n",
    "    correct = (predictions == dataset.test.targets).cpu().numpy()\n",
    "    \n",
    "    test_results = conditions.copy()\n",
    "    test_results['probability'] = goal_probs\n",
    "    test_results['correct'] = correct\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for different training set size (i.e. number of puzzles in Practice Phase)\n",
    "\n",
    "all_train_results = []\n",
    "all_test_results = []\n",
    "for num_train in tqdm([25, 50, 100, 200, 300, 400, 500]):\n",
    "    model = RRN(digit_embed_size=10,\n",
    "                hidden_vector_size=48,\n",
    "                message_size=48).to(device)\n",
    "    dataset, conditions = create_dataset(num_train=num_train, num_valid=100)\n",
    "    train_results = train_model(model, dataset, num_epochs=1000, record_epoch=10, verbose=False)\n",
    "    test_results = get_test_results(model, dataset, conditions)\n",
    "    train_results['train_size'] = num_train\n",
    "    test_results['train_size'] = num_train\n",
    "    \n",
    "    all_train_results.append(train_results)\n",
    "    all_test_results.append(test_results)\n",
    "    \n",
    "train_results = pd.concat(all_train_results)\n",
    "test_results = pd.concat(all_test_results)\n",
    "\n",
    "train_results = train_results[['train_size', 'epoch', 'loss', 'accuracy', 'probability']]\n",
    "test_results = test_results[['train_size', 'house_type', 'house_index', 'cell_index',\n",
    "                             'digit_set', 'correct', 'probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "dirpath = proj_path + 'data/rrn/'\n",
    "utils.mkdir(dirpath)\n",
    "\n",
    "train_results.to_csv(dirpath + \"train_results.tsv\", sep='\\t', index=False)\n",
    "test_results.to_csv(dirpath + \"test_results.tsv\", sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
