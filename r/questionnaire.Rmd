---
title: "questionnaire"
author: "Andrew"
date: "01/26/2021"
output:
  pdf_document:
    number_sections: true
---

This file analyzes questionnaire ratings data.

```{r setup, include=FALSE}
# these options here change the formatting of how comments are rendered
knitr::opts_chunk$set(collapse = TRUE,
                      comment = "#>",
                      results = "hold",
                      fig.show = "hold")

# Disable this warning
options(dplyr.summarise.inform = FALSE)

# Clear any existing variables
rm(list = ls())
```

```{r libraries, echo=F, message=FALSE}
library(lme4)
library(glue)
library(broom.mixed)
library(brms)
library(BayesianFirstAid)
library(ggdist)
library(stringr)
library(tidyverse)

source("functions.R")
```

```{r plot_theme, echo=F}
# Set ggplot theme
theme_set(theme_light() +
            theme(plot.title = element_text(hjust = 0.5)))
```

```{r load_data, echo=F, message=F, warning=F}
df.subject_data = read_tsv("../data/processed/subject_data.tsv")
df.results = read_tsv("../data/processed/puzzle_data.tsv")
df.qratings1 = read_tsv("../data/qratings/rater1.tsv", quote = "") %>% 
  mutate(rater = 'rater1')
df.qratings2 = read_tsv("../data/qratings/rater2.tsv", quote = "") %>%
  mutate(rater = 'rater2')
```

```{r wrangle, echo=F}
categories = c('V1', 'V2', 'V3', 'U1', 'U2', 'I1', 'I2', 'I3', 'M', 'X')

df.qratings = df.qratings1 %>% 
  bind_rows(df.qratings2) %>% 
  select(sid_hash,
         rater,
         correct_eval = Evaluation,
         correct_actual = Actual,
         pd = PD,
         aoe = AoE,
         basis = `Basis for Choice`,
         basis2 = `Second Choice`,
         notes = `Additional Notes`) %>% 
  replace_na(list(basis2 = 'K')) %>% 
  mutate(correct_eval = correct_eval == 'Correct',
         correct_actual = correct_actual == 'Correct',
         pd = ifelse(pd == 'Vague or uncertain', 'Uncertain', pd),
         pd = factor(pd, levels = c('Both',
                                    'Target',
                                    'Distractor',
                                    'Neither',
                                    'Uncertain')),
         aoe = aoe == 'Yes with explanation',
         basis = substring(basis, 0, 1),
         basis2 = substring(basis2, 0, 1),
         basis = case_when(basis == 'A' ~ 'V1',
                           basis == 'B' ~ 'V2',
                           basis == 'C' ~ 'V3',
                           basis == 'D' ~ 'U1',
                           basis == 'E' ~ 'I1',
                           basis == 'F' ~ 'I2',
                           basis == 'G' ~ 'I3',
                           basis == 'H' ~ 'U2',
                           basis == 'I' ~ 'M',
                           TRUE ~ 'X'),
         basis2 = case_when(basis2 == 'A' ~ 'V1',
                            basis2 == 'B' ~ 'V2',
                            basis2 == 'C' ~ 'V3',
                            basis2 == 'D' ~ 'U1',
                            basis2 == 'E' ~ 'I1',
                            basis2 == 'F' ~ 'I2',
                            basis2 == 'G' ~ 'I3',
                            basis2 == 'H' ~ 'U2',
                            basis2 == 'I' ~ 'M',
                            TRUE ~ 'X'),
         basis = factor(basis, categories),
         basis2 = factor(basis2, categories),
         valid_basis = basis %in% c("V1", "V2", "V3"))

df.data = df.subject_data %>% 
  right_join(df.qratings, by = "sid_hash") %>% 
  mutate(solver = ifelse(solver, "Persistent Solver", "PD Guesser") %>% 
           factor(levels = c('Persistent Solver', 'PD Guesser')))
```

# Forced-response questions

```{r wrangle_mc, echo=F}
df.attn = df.data %>% 
  select(subject_id, solver, q_attn_check1, q_attn_check2, q_attn_check3) %>% 
  distinct() %>% 
  mutate(q_attn_check3 = 1 - q_attn_check3) %>% 
  pivot_longer(c(q_attn_check1, q_attn_check2, q_attn_check3),
               names_to = "temp",
               values_to = "value") %>% 
  select(-temp) %>% 
  mutate(measure = "Attention Check",
         value = as.numeric(value))

df.questions_long = df.data %>% 
  select(subject_id,
         solver,
         q_puzzle,
         q_confidence,
         q_digit_selection,
         q_digit_check,
         q_check_strategy_select) %>% 
  distinct() %>%  
  mutate(q_puzzle = q_puzzle == 'target',
         q_digit_selection = str_sub(q_digit_selection, 0, 3) == 'I n',
         q_digit_check = str_sub(q_digit_check, 0, 3) == 'Yes',
         q_check_strategy_select = str_sub(q_check_strategy_select, 0, 3) != 'I l',
         solved = q_puzzle == 'target',
         q_confidence = q_confidence / 100) %>% 
  pivot_longer(-c(subject_id, solver),
               names_to = "measure",
               values_to = "value") %>% 
  bind_rows(df.attn) %>% 
  mutate(measure = recode(measure,
                          q_puzzle = "Solved\nPuzzle",
                          q_confidence = "Puzzle\nConfidence",
                          q_digit_selection = "Noticed",
                          q_digit_check = "Checked\nCandidate",
                          q_check_strategy_select = "Checked\nHouse"),
         measure = factor(measure,
                          levels = c("Attention\nCheck",
                                     "Solved\nPuzzle",
                                     "Puzzle\nConfidence",
                                     "Noticed",
                                     "Checked\nCandidate",
                                     "Checked\nHouse"))) %>% 
  drop_na()
```

Forced-response summary statistics

```{r mc_stats}
set.seed(0)

df.sum.stats = df.questions_long %>% 
  group_by(measure, solver) %>% 
  summarize(n = n(),
            mean = mean(value)) %>% 
  left_join(get_beta_hdci(df.questions_long,
                          value,
                          100000,
                          c('solver', 'measure'),
                          seed=0)) %>% 
  mutate(across(where(is.numeric), ~round(., 4)))
```

## Difference in means
```{r}
set.seed(0)

binom_prop_diff = function(df, counts, total) {
  # counts and total must be integer columns
  counts = pull(df, !!enquo(counts))
  total = pull(df, !!enquo(total))
  means = counts / total
  means = c(means, means[1] - means[2])
  results = bayes.prop.test(counts, total)
  results$stats %>% 
    as.tibble(rownames='term') %>% 
    mutate(term = case_when(term == 'theta[1]' ~ 'group1',
                            term == 'theta[2]' ~ 'group2',
                            term == 'theta_diff[1,2]' ~ 'diff')) %>%
    filter(term %in% c('group1', 'group2', 'diff')) %>% 
    mutate(mean = means) %>% 
    select(term, mean, hdci_l = HDIlo, hdci_u = HDIup)
}

df.sum.stats %>% 
  mutate(alpha = as.integer(alpha)) %>% 
  group_by(measure) %>% 
  nest() %>% 
  mutate(results = map(data, ~binom_prop_diff(., alpha, n))) %>%
  select(-data) %>% 
  unnest() %>% 
  mutate(across(where(is.numeric), ~round(100*., 2)))
```

## Plot

```{r mc_bar, echo=F}
# Forced-response bar plot
ggplot() +
  stat_summary(aes(x = measure, y = value, fill = solver),
               data = df.questions_long,
               fun = "mean",
               geom = "bar",
               position = position_dodge2()) +
  geom_linerange(aes(x = measure,
                     ymin = hdci_l,
                     ymax = hdci_h,
                     group = solver),
                 data = df.sum.stats,
                 position = position_dodge2(.9)) +
  geom_text(aes(x = measure, y = -.06, label = n, group = solver),
            data = df.sum.stats,
            vjust=0,
            position = position_dodge(width = .9)) +
  labs(x = "Question",
       y = "Response") +
  theme(legend.title = element_blank(),
        legend.position = "bottom") +
  ggsave(glue("../figures/questionnaire/q_mc.png"), width=6, height=4)
```

# Free-response questions

## Did the raters correctly judge the correctness of subjects' responses?
```{r rater_correct}
df.data %>% 
  mutate(correct_acc = correct_eval == correct_actual) %>% 
  group_by(rater) %>% 
  summarize(correct_acc = mean(correct_acc)) %>% 
  knitr::kable()
```

## Did the raters agree on their decisions?

### PD

```{r pd_agree}
df.data %>% 
  select(subject_id, rater, pd) %>% 
  pivot_wider(names_from = rater, values_from = pd) %>% 
  mutate(agree = rater1 == rater2) %>% 
  summarize(agree = mean(agree)) %>% 
  knitr::kable()
```

```{r pd_tile, echo=F}
# PD Agreement plot

df.data %>% 
  select(subject_id, rater, pd) %>% 
  pivot_wider(names_from = rater, values_from = pd) %>% 
  group_by(rater1, rater2) %>% 
  summarize(n = n()) %>% 
  complete(rater1, rater2, fill = list(n = 0)) %>% 
  mutate(label = ifelse(n > 0, as.character(n), "")) %>% 
  ggplot(aes(x = rater1, y = fct_rev(rater2), fill = n)) +
  geom_tile() +
  scale_fill_gradient(low = 'white',
                      high = 'steelblue',
                      na.value = 'white') +
  geom_text(aes(label = label)) +
  scale_x_discrete(position = "top") + 
  theme(legend.position = "bottom",
        text = element_text(size = 15)) +
  labs(title = 'Prevalent Digit Classifications',
       x = 'Rater 1',
       y = 'Rater 2') +
  guides(fill = guide_colorbar(title = "Number of Subjects")) + 
  ggsave(glue("../figures/questionnaire/q_pd.png"), width=6, height=4)
```

### Awareness of Error
```{r aoe_agree}
df.data %>% 
  select(subject_id, rater, aoe) %>% 
  drop_na(aoe) %>% 
  pivot_wider(names_from = rater, values_from = aoe) %>% 
  mutate(agree = rater1 == rater2) %>% 
  summarize(agree = mean(agree)) %>% 
  knitr::kable()
```

### Basis for Choice

First choice only
```{r}
df.data %>% 
  select(subject_id, rater, basis) %>% 
  mutate(basis = as.character(basis)) %>% 
  pivot_wider(names_from = rater,
              values_from = basis,
              names_glue = "{rater}_{.value}") %>% 
  mutate(agree = rater1_basis == rater2_basis) %>% 
  select(subject_id, agree, everything()) %>% 
  summarize(agree = mean(agree)) %>% 
  knitr::kable()
```


First choice only for those that solved correctly at valid vs invalid
```{r}
df.data %>% 
  filter(correct_actual) %>% 
  #        solver == 'Persistent Solver') %>% 
  select(subject_id, rater, basis) %>% 
  # mutate(basis = as.character(basis)) %>%
  mutate(basis = as.character(basis) %>%
           substring(0, 1)) %>%
  pivot_wider(names_from = rater,
              values_from = basis,
              names_glue = "{rater}_{.value}") %>% 
  mutate(agree = rater1_basis == rater2_basis) %>% 
  select(subject_id, agree, everything()) %>% 
  summarize(agree = mean(agree)) %>% 
  knitr::kable()
```

Rule: Either both first bases match or a first basis match with second basis.
Since our focus on this analysis is just first basis, if only second bases match,
we should just count them as disagreements.

```{r basis_agree}
df.data %>% 
  select(subject_id, rater, basis, basis2) %>% 
  mutate(across(c(basis, basis2),
                .fns = as.character)) %>% 
  pivot_wider(names_from = rater,
              values_from = c('basis', 'basis2'),
              names_glue = "{rater}_{.value}") %>% 
  mutate(agree = rater1_basis == rater2_basis | 
           rater1_basis == rater2_basis2 |
           rater1_basis2 == rater2_basis) %>% 
  select(subject_id, agree, everything()) %>% 
  summarize(agree = mean(agree)) %>% 
  knitr::kable()
```


```{r basis_tile, echo=F}
# Visualizing only first bases.

df.data %>% 
  select(subject_id, solver, rater, basis) %>% 
  pivot_wider(names_from = rater, values_from = basis) %>% 
  group_by(rater1, rater2, solver) %>% 
  summarize(n = n()) %>% 
  complete(rater1, rater2, fill = list(n = 0)) %>% 
  mutate(label = ifelse(n > 0, as.character(n), "")) %>% 
  drop_na(solver) %>% 
  ggplot(aes(x = rater1, y = fct_rev(rater2), fill = n)) +
  geom_tile() +
  scale_fill_gradient(low = 'white',
                      high = 'steelblue',
                      na.value = 'white') +
  geom_text(aes(label = label)) +
  scale_x_discrete(position = "top") + 
  facet_wrap(vars(solver)) +
  theme(legend.position = "bottom",
        text = element_text(size = 15)) +
  labs(title = 'Basis for Choice Classifications',
       x = 'Rater 1',
       y = 'Rater 2') +
  guides(fill = guide_colorbar(title = "Number of Subjects")) +
  ggsave(glue("../figures/questionnaire/q_basis.png"), width=6, height=4)
```

```{r basis_tile, echo=F}
# Visualizing only first bases.
# Correct responders only

df.data %>% 
  filter(correct_actual) %>% 
  select(subject_id, solver, rater, basis) %>% 
  pivot_wider(names_from = rater, values_from = basis) %>% 
  group_by(rater1, rater2, solver) %>% 
  summarize(n = n()) %>% 
  complete(rater1, rater2, fill = list(n = 0)) %>% 
  mutate(label = ifelse(n > 0, as.character(n), "")) %>% 
  drop_na(solver) %>% 
  ggplot(aes(x = rater1, y = fct_rev(rater2), fill = n)) +
  geom_tile() +
  scale_fill_gradient(low = 'white',
                      high = 'steelblue',
                      na.value = 'white') +
  geom_text(aes(label = label)) +
  scale_x_discrete(position = "top") + 
  facet_wrap(vars(solver)) +
  theme(legend.position = "bottom",
        text = element_text(size = 15)) +
  labs(title = 'Basis for Choice Classifications (Correct Only)',
       x = 'Rater 1',
       y = 'Rater 2') +
  guides(fill = guide_colorbar(title = "Number of Subjects")) +
  ggsave(glue("../figures/questionnaire/q_basis_correct.png"), width=6, height=4)
```

## Basis for Choice Group Differences

Difference in valid_basis distribution
```{r basis_tests, warning=F}
df.data %>% 
  filter(correct_actual) %>% 
  get_counts_with_zeros(c('solver', 'valid_basis')) %>% 
  spread(valid_basis, n) %>% 
  select(-solver) %>% 
  chisq.test()
```

All 9 classifications

```{r}
df.data %>% 
  filter(correct_actual) %>% 
  get_counts_with_zeros(c('solver', 'basis')) %>% 
  spread(basis, n) %>% 
  select(-c(solver, X)) %>% 
  chisq.test()
```

## Basis Plot

```{r basis_bar, echo=F}
# Bar plot
df = df.data %>% 
  filter(correct_actual) %>% 
  select(subject_id, rater, solver, basis)

df.sum.stats = get_dirichlet_hdci(df, c('solver', 'basis'), 100000) %>% 
  mutate(category = factor(basis, categories))

df %>%
  crossing(category = categories) %>% 
  mutate(selected = as.numeric(category == basis),
         category = factor(category, categories, ordered = TRUE)) %>% 
  ggplot(aes(x = category, color = solver, group = solver)) +
  stat_summary(aes(y = selected),
               fun = "mean",
               geom = "point",
               size = 2,
               position = position_dodge2(.5)) +
  geom_linerange(aes(ymin = hdci_l,
                     ymax = hdci_h),
                 data = df.sum.stats,
                 position = position_dodge2(.5)) +
  coord_cartesian(ylim = c(-.02, .52)) + 
  scale_y_continuous(breaks = c(0, .25, .5)) +
  theme(legend.title = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        legend.position = c(.81, .85),
        text = element_text(size = 15)) +
  labs(x = "Basis",
       y = "% of Participants in Group") +
  ggsave(glue("../figures/questionnaire/q_ratings.png"), width=6, height=4)
```


# Education
```{r edu_wrangle, echo=F, message=F}
df.edu = df.subject_data %>% 
  mutate(edu_level = factor(education,
                            levels = c('no_hs',
                                       'hs',
                                       'asso',
                                       'bach',
                                       'mast',
                                       'prof',
                                       'phd'),
                            labels = c('HS\nIncomplete',
                                       'High\nSchool',
                                       "Associate's",
                                       "Bachelor's",
                                       "Master's",
                                       'Professional',
                                       'Doctoral')),
         education = recode(education,
                            phd = 21,
                            prof = 20,
                            mast = 18,
                            bach = 16,
                            asso = 14,
                            hs = 12,
                            no_hs = 10)) %>% 
  select(subject_id, sid_hash, solver,
         education, edu_level, starts_with('m_')) %>% 
  rename_with(~str_sub(., start=3), starts_with('m_')) %>% 
  mutate(across(where(is_logical), as.numeric),
         in_qrate = sid_hash %in% df.qratings1$sid_hash,
         alg_geom = case_when(alg + geom == 2 ~ 'Both',
                              alg + geom == 1 ~ 'One',
                              alg + geom == 0 ~ 'Neither'),
         alg_geom = factor(alg_geom,
                           levels = c("Both", "One", "Neither")))

df.edu = df.results %>% 
  group_by(subject_id) %>% 
  summarize(n_solved = sum(correct),
            accuracy = mean(correct)) %>% 
  left_join(df.edu)
```


```{r}
model = brm(accuracy ~ 0 + alg_geom:edu_level,
            data = df.edu,
            prior = c(set_prior("uniform(0,1)", lb = 0, ub = 1)),
            save_pars = save_pars(all=TRUE),
            seed = 0,
            iter = 4000,
            cores = 4,
            refresh = 0,
            file = 'cache/edu.plot')

df.sum.stats = model %>% 
  tidy() %>% 
  select(term, estimate, conf.low, conf.high) %>% 
  mutate(alg_geom = map_chr(term, ~ str_match(., "alg\\_geom*(.*?):edu\\_level")[,2]),
         edu_level = map_chr(term, ~ sub('.*edu_level', '', .) %>% 
                               gsub("([A-Z])", " \\1", .) %>% 
                               substr(., 2, 1000))) %>% 
  select(alg_geom, edu_level, estimate, hdci_l = conf.low, hdci_h = conf.high) %>% 
  mutate(edu_level = case_when(edu_level == 'H S Incomplete' ~ 'HS\nIncomplete',
                               edu_level == 'High School' ~ 'High\nSchool',
                               edu_level == 'Associates' ~ "Associate's",
                               edu_level == 'Bachelors' ~ "Bachelor's",
                               edu_level == 'Masters' ~ "Master's",
                               TRUE ~ edu_level),
         alg_geom = factor(alg_geom, levels(df.edu$alg_geom)))

df.sum.stats = df.edu %>% 
  get_counts_with_zeros(c('edu_level', 'alg_geom')) %>% 
  inner_join(df.sum.stats) %>% 
  mutate(hdci_h = case_when(n < 2 ~ hdci_l,
                            TRUE ~ hdci_h)) %>% 
  filter(n > 0)


colors = hue_pal()(3)

df.edu %>% 
  ggplot(aes(x = edu_level,
             color = alg_geom,
             fill = alg_geom)) +
  geom_point(aes(y = accuracy),
             position = position_jitterdodge(dodge.width = .3,
                                             jitter.width = .3),
             alpha = .5) +
  geom_linerange(aes(ymin = hdci_l,
                     ymax = hdci_h),
                 data = df.sum.stats,
                 size = .75,
                 position = position_dodge2(.3)) +
  stat_summary(aes(y = accuracy),
               fun = "mean",
               geom = "point",
               size = 2,
               shape = 21,
               color = 'black',
               position = position_dodge2(.3)) +
  scale_color_manual(values = c(colors[2], 'gold', colors[1])) +
  scale_fill_manual(values = c(colors[2], 'gold', colors[1])) +
  labs(x = "Education",
       y = "Accuracy",
       color = "Algebra & Geometry",
       fill = "Algebra & Geometry") +
  theme(legend.position = "bottom",
        text = element_text(size = 15)) +
  ggsave(glue("../figures/questionnaire/education.png"), width=7, height=5)
```

## Regressions

### Education
```{r fit_edu}
lm.edu = brm(n_solved ~ education,
             data = df.edu,
             save_pars = save_pars(all=TRUE),
             seed = 0,
             cores = 4,
             refresh = 0,
             file = 'cache/education/edu')

lm.edu %>%
  summary() %>% 
  print(digits = 3)

bayes_R2(lm.edu)
```

### Math
```{r fit_math}
lm.math = brm(n_solved ~ alg + geom + trig + sv_calc +
                mv_calc + linalg + pr_stat + disc + logic,
              data = df.edu,
              save_pars = save_pars(all=TRUE),
              seed = 0,
              cores = 4,
              refresh = 0,
              file = 'cache/education/math')

lm.math %>%
  summary() %>% 
  print(digits = 3)

bayes_R2(lm.math)
```

### Algebra and Geometry
```{r fit_ag}
lm.ag = brm(n_solved ~ alg + geom,
            data = df.edu,
            save_pars = save_pars(all=TRUE),
            seed = 0,
            cores = 4,
            refresh = 0,
            file = 'cache/education/ag')

lm.ag %>%
  summary() %>% 
  print(digits = 3)

bayes_R2(lm.ag)
```

### Education, algebra, and geometry
```{r fit_eag}
lm.eag = brm(n_solved ~ education + alg + geom,
             data = df.edu,
             save_pars = save_pars(all=TRUE),
             seed = 0,
             cores = 4,
             refresh = 0,
             file = 'cache/education/eag')

lm.eag %>%
  summary() %>% 
  print(digits = 3)

bayes_R2(lm.eag)
```

### Education and math
```{r fit_all}
lm.all = brm(n_solved ~ education + alg + geom + trig + sv_calc +
               mv_calc + linalg + pr_stat + disc + logic,
             data = df.edu,
             save_pars = save_pars(all=TRUE),
             seed = 0,
             cores = 4,
             refresh = 0,
             file = 'cache/education/all')

lm.all %>%
  summary()

bayes_R2(lm.all)
```

### Compare models

Education does not substantially improve the models when all the math courses are
accounted for. It is more substantial (moderately strong evidence) when only considering
algebra and geometry.
```{r}
bayes_factor(lm.all, lm.math, silent=T)
bayes_factor(lm.eag, lm.ag, silent=T)
```

Conversely, considering algebra and geometry is extremely helpful compared to just
years of education.

```{r}
bayes_factor(lm.eag, lm.edu, silent=T)
```

The BF shows extremely high favor towards including other math courses. It certainly
adds predictive power collectively, but the significance of individual terms is unclear.
```{r}
bayes_factor(lm.all, lm.eag, silent=T)
bayes_factor(lm.math, lm.ag, silent=T)
```



## Compare distributions of alg_geom

```{r ag_dist}
df.edu %>% 
  filter(sid_hash %in% df.qratings$sid_hash) %>% 
  get_counts_with_zeros(c('solver', 'alg_geom')) %>% 
  pivot_wider(names_from = alg_geom,
              values_from = n) %>% 
  select(solver, Both, One, Neither) %>% 
  replace_na(list(Neither = 0)) %>% 
  select(-solver) %>% 
  chisq.test()
```
